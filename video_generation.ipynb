{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic libraries\n",
    "import os\n",
    "import gc \n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# library for image augmentation\n",
    "from albumentations import Compose, Resize\n",
    "\n",
    "# library for unet model\n",
    "from denoising_diffusion_pytorch import Unet\n",
    "\n",
    "# library for VQGAN encode/decoder\n",
    "from river.model import Model\n",
    "from river.lutils.configuration import Configuration\n",
    "\n",
    "# library for stochastic interpolators with follmer processes\n",
    "import ProbForecastFollmerProcess as pffp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing on cuda\n"
     ]
    }
   ],
   "source": [
    "# setting plotting style and defining the device\n",
    "plt.style.use('ggplot')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data_folder = \"./store/multi_modal_jump_diffusion\"\n",
    "print('Computing on ' + str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data paths\n",
    "# defining root to CLEVREV data\n",
    "CLEVREV_root = \"store/video_generation/data/CLEVREV\"\n",
    "# defining base folder of CLEVREV train, validation and test data\n",
    "CLEVREV_train_folder = os.path.join(CLEVREV_root, \"video_train\")\n",
    "CLEVREV_validation_folder = os.path.join(CLEVREV_root, \"video_validation\")\n",
    "CLEVREV_test_folder = os.path.join(CLEVREV_root, \"video_test\")\n",
    "# defining video folders of CLEVEREV train, validation and test data\n",
    "CLEVREV_train_video_folders = [os.path.join(CLEVREV_train_folder, video_folder) for video_folder in os.listdir(CLEVREV_train_folder)]\n",
    "CLEVREV_validation_video_folders = [os.path.join(CLEVREV_validation_folder, video_folder) for video_folder in os.listdir(CLEVREV_validation_folder)]\n",
    "CLEVREV_test_video_folders = [os.path.join(CLEVREV_test_folder, video_folder) for video_folder in os.listdir(CLEVREV_test_folder)]\n",
    "# defining video files for each of the CLEVEREV train, validation and test data\n",
    "CLEVRER_train_video_paths = [os.path.join(video_folder, mp4_file) for video_folder in CLEVREV_train_video_folders for mp4_file in os.listdir(video_folder)]\n",
    "CLEVRER_validation_video_paths = [os.path.join(video_folder, mp4_file) for video_folder in CLEVREV_validation_video_folders for mp4_file in os.listdir(video_folder)]\n",
    "CLEVRER_test_video_paths = [os.path.join(video_folder, mp4_file) for video_folder in CLEVREV_test_video_folders for mp4_file in os.listdir(video_folder)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset and transforms\n",
    "# defining target frame heght and width\n",
    "target_frame_height = target_frame_width = 128\n",
    "# defining custom train, validation and test augmentations\n",
    "train_augmentations = Compose([Resize(target_frame_height, target_frame_width)])\n",
    "validation_augmentations = Compose([Resize(target_frame_height, target_frame_width)])\n",
    "test_augmentations = Compose([Resize(target_frame_height, target_frame_width)])\n",
    "# defining datasets\n",
    "CLEVREV_train_dataset = pffp.data.VideoDataset(CLEVRER_train_video_paths, augmentations = train_augmentations)\n",
    "CLEVREV_validation_dataset = pffp.data.VideoDataset(CLEVRER_validation_video_paths, augmentations = validation_augmentations)\n",
    "CLEVREV_test_dataset = pffp.data.VideoDataset(CLEVRER_test_video_paths, augmentations = test_augmentations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model's weights and configuration\n",
    "# defining root to CLEVREV weights\n",
    "CLEVREV_weights_root = \"store/video_generation/weights\"\n",
    "# defining path to VQVAE CLEVREV weights\n",
    "VQVAE_CLEVREV_weights_path = os.path.join(CLEVREV_weights_root, \"vqvae.pth\")\n",
    "# defining path to VQGAN CLEVREV weights\n",
    "VQGAN_CLEVREV_weights_path = os.path.join(CLEVREV_weights_root, \"model.pth\")\n",
    "# defining path to CLEVREV configuration\n",
    "CLEVREV_config_path = \"store/video_generation/configs/clevrer.yaml\"\n",
    "# initializing configurations\n",
    "CLEVEREV_configuration = Configuration(CLEVREV_config_path)\n",
    "# initializing model\n",
    "CLEVREV_model = Model(CLEVEREV_configuration[\"model\"]).to(device)\n",
    "# getting the encoder\n",
    "CLEVREV_VQGAN_encoder = CLEVREV_model.ae.backbone.encoder\n",
    "# getting the decoder\n",
    "CLEVREV_VQGAN_decoder = CLEVREV_model.ae.backbone.decoder\n",
    "# defining latent datasets\n",
    "CLEVREV_latent_train_dataset = pffp.data.VQGANLatentVideoDataset(CLEVREV_train_dataset, CLEVREV_VQGAN_encoder, device)\n",
    "CLEVREV_latent_validation_dataset = pffp.data.VQGANLatentVideoDataset(CLEVREV_validation_dataset, CLEVREV_VQGAN_encoder, device)\n",
    "CLEVREV_latent_test_dataset = pffp.data.VQGANLatentVideoDataset(CLEVREV_test_dataset, CLEVREV_VQGAN_encoder, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining function for creating a lagged dataset with random context from a tensor holding a video\n",
    "def get_video_dataset_with_random_context(video_tensor):\n",
    "    target_frame, past_frame, random_context_frame = pffp.utils.pair_lagged_observations_with_random_context(video_tensor)\n",
    "    video_dataset_with_random_context = pffp.data.LaggedDatasetWithRandomContext(past_frame, target_frame, random_context_frame, device)\n",
    "    return video_dataset_with_random_context"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion-models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
